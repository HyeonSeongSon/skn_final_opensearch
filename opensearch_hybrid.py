from opensearchpy import OpenSearch, exceptions, helpers
from sentence_transformers import SentenceTransformer
from FlagEmbedding import FlagReranker
from dotenv import load_dotenv
from typing import List, Dict, Any, Union
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
import numpy as np
import logging
import json
import os
import math

load_dotenv()

class OpenSearchHybridClient:
    def __init__(self):
        """
        OpenSearch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë° ì—°ê²° ì„¤ì • (í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ ê¸°ë°˜)
        """
        try:
            password = os.getenv("OPENSEARCH_ADMIN_PASSWORD")
            if not password:
                logging.warning("í™˜ê²½ ë³€ìˆ˜ OPENSEARCH_ADMIN_PASSWORDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                password = "StrongP@ssw0rd123!"
            
            logging.info(f"OpenSearch ì—°ê²° ì‹œë„ ì¤‘... (ë¹„ë°€ë²ˆí˜¸ ê¸¸ì´: {len(password)})")
            
            host = os.getenv("OPENSEARCH_HOST", "localhost")
            port = int(os.getenv("OPENSEARCH_PORT", "9200"))
            
            logging.info(f"OpenSearch ì—°ê²° ëŒ€ìƒ: {host}:{port}")
            
            self.client = OpenSearch(
                hosts=[{"host": host, "port": port}],
                timeout=30,
            )
            
            if not self.client.ping():
                raise exceptions.ConnectionError("OpenSearchì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            logging.info("OpenSearchì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except exceptions.OpenSearchException as e:
            logging.error(f"OpenSearch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.client = None

        self.model = self.embeddings_model()
        self.reranker = self.rerank_model()
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        self.keyword_prompt = {
            "prompts": {
                "keyword_extraction": """
                ë‹¹ì‹ ì€ ë°˜ë“œì‹œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
                ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ë°˜ë“œì‹œ ì¶”ì¶œí•˜ì„¸ìš”.

                "{user_question}"

                ì•„ë˜ ì¡°ê±´ì„ ë§Œì¡±í•´ì„œ ì¶œë ¥í•˜ì„¸ìš”.

                1. í‚¤ì›Œë“œëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜ë“œì‹œ ì¶œë ¥

                2. ë¬¸ìì—´ì€ í°ë”°ì˜´í‘œë¡œ ê°ì‹¸ì„œ ì¶œë ¥í•˜ì„¸ìš”.

                3. ë¦¬ìŠ¤íŠ¸ì™¸ì—ëŠ” ì•„ë¬´ê²ƒë„ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

                4. í‚¤ì›Œë“œëŠ” ìµœëŒ€ 5ê°œê¹Œì§€ ì¶”ì¶œí•˜ì„¸ìš”.

                5. ë³µí•©ì–´ëŠ” ë¶„í•´í•´ì„œ ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì¤˜

                ì˜ˆë¥¼ ë“¤ì–´ 'ì„ì§ì› êµìœ¡ê¸°ê°„'ì´ë¼ë©´ 'ì„ì§ì›', 'êµìœ¡', 'ê¸°ê°„'ì²˜ëŸ¼ ë‚˜ëˆ ì¤˜.
                """
            }
        }

    def rerank_model(self):
        """
        BGE Reranker ëª¨ë¸ ì´ˆê¸°í™” (ë¦¬ë­í¬ìš©)
        """
        print("BGE Reranker ëª¨ë¸ ë¡œë“œ ì¤‘...")
        reranker = FlagReranker('dragonkue/bge-reranker-v2-m3-ko', use_fp16=True)
        print("BGE Reranker ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        return reranker

    def embeddings_model(self):
        """
        ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        """
        model = SentenceTransformer("dragonkue/snowflake-arctic-embed-l-v2.0-ko") 
        vec_dim = len(model.encode("dummy_text"))
        print(f"ëª¨ë¸ ì°¨ì›: {vec_dim}")
        return model
    
    def get_keyword(self, user_input):
        keyword_template = self.keyword_prompt.get("prompts", {}).get("keyword_extraction", "")
        template = ChatPromptTemplate.from_template(keyword_template)
        messages = template.format_messages(user_question=user_input)
        response = self.llm.invoke(messages)
        return response.content

    def delete_index(self, index_name: str) -> None:
        """
        ì¸ë±ìŠ¤ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
        """
        if not self.client:
            logging.error("í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì¸ë±ìŠ¤ë¥¼ ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        try:
            if self.client.indices.exists(index=index_name):
                self.client.indices.delete(index=index_name)
                logging.info(f"'{index_name}' ì¸ë±ìŠ¤ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
        except exceptions.OpenSearchException as e:
            logging.error(f"ì¸ë±ìŠ¤ ì‚­ì œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def index_document(self, index_name: str, document: dict, refresh: bool = False) -> dict | None:
        """
        ì£¼ì–´ì§„ ì¸ë±ìŠ¤ì— ë¬¸ì„œë¥¼ ìƒ‰ì¸í•©ë‹ˆë‹¤.
        """
        if not self.client:
            logging.error("í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ë¬¸ì„œë¥¼ ìƒ‰ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        try:
            params = {"refresh": "true" if refresh else "false"}
            response = self.client.index(index=index_name, body=document, params=params)
            logging.info(f"'{index_name}' ì¸ë±ìŠ¤ì— ë¬¸ì„œ ID '{response['_id']}'ë¡œ ìƒ‰ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return response
        except exceptions.RequestError as e:
            logging.error(f"ë¬¸ì„œ ìƒ‰ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì˜ëª»ëœ ìš”ì²­): {e}")
        except exceptions.OpenSearchException as e:
            logging.error(f"ë¬¸ì„œ ìƒ‰ì¸ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

    def bulk_index_documents(self, index_name: str, documents: list[dict], refresh: bool = False) -> bool:
        """
        ì£¼ì–´ì§„ ì¸ë±ìŠ¤ì— ì—¬ëŸ¬ ë¬¸ì„œë¥¼ bulkë¡œ ìƒ‰ì¸í•©ë‹ˆë‹¤.
        """
        if not self.client:
            logging.error("í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ë¬¸ì„œë¥¼ ìƒ‰ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        actions = [
            {"_index": index_name, "_source": doc}
            for doc in documents
        ]

        try:
            success, failed = helpers.bulk(self.client, actions, refresh=refresh)
            logging.info(f"Bulk ì‘ì—… ì™„ë£Œ: ì„±ê³µ {success}ê±´, ì‹¤íŒ¨ {len(failed)}ê±´")
            return not failed
        except exceptions.OpenSearchException as e:
            logging.error(f"Bulk ìƒ‰ì¸ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
    
    def search_document(self, index_name: str, query: dict) -> list[dict]:
        """
        ì£¼ì–´ì§„ ì¿¼ë¦¬ë¡œ ì¸ë±ìŠ¤ì—ì„œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        """
        if not self.client:
            logging.error("í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        try:
            response = self.client.search(index=index_name, body=query)
            hits = response["hits"]["hits"]
            logging.info(f"'{index_name}' ì¸ë±ìŠ¤ì—ì„œ {len(hits)}ê°œì˜ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            return [{"score": hit["_score"], "source": hit["_source"]} for hit in hits]
        except exceptions.NotFoundError:
            logging.warning(f"ê²€ìƒ‰ ì‹¤íŒ¨: '{index_name}' ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        except exceptions.RequestError as e:
            logging.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì˜ëª»ëœ ì¿¼ë¦¬): {e}")
        except exceptions.OpenSearchException as e:
            logging.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []
    
    def create_index_with_mapping(self, index_name: str, mapping: dict) -> bool:
        """
        ì§€ì •í•œ ë§¤í•‘ìœ¼ë¡œ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        """
        if not self.client:
            logging.error("í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        try:
            if not self.client.indices.exists(index=index_name):
                self.client.indices.create(index=index_name, body=mapping)
                logging.info(f"'{index_name}' ì¸ë±ìŠ¤ë¥¼ ë§¤í•‘ê³¼ í•¨ê»˜ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
                return True
            logging.info(f"'{index_name}' ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
            return True
        except exceptions.RequestError as e:
            logging.error(f"ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì˜ëª»ëœ ë§¤í•‘): {e}")
        except exceptions.OpenSearchException as e:
            logging.error(f"ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False
    
    def load_documents_from_jsonl(self, file_path: str) -> list[dict]:
        """
        JSONL íŒŒì¼ì—ì„œ ë¬¸ì„œë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        """
        documents = []
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                for line in file:
                    line = line.strip()
                    if line:
                        doc = json.loads(line)
                        documents.append(doc)
            logging.info(f"'{file_path}'ì—ì„œ {len(documents)}ê°œ ë¬¸ì„œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        except FileNotFoundError:
            logging.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        except json.JSONDecodeError as e:
            logging.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        except Exception as e:
            logging.error(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return documents

    def rerank_documents(self, query_text, documents, top_k=3):
        """
        BGE Rerankerë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë¦¬ë­í¬
        """
        print(f"\n=== BGE Reranker ë¦¬ë­í¬ ì‹œì‘ ===")
        print(f"ë¦¬ë­í¬ ëŒ€ìƒ ë¬¸ì„œ: {len(documents)}ê°œ")
        print(f"ë¦¬ë­í¬ í›„ ë°˜í™˜: ìƒìœ„ {top_k}ê°œ")
        
        if not documents:
            return []
        
        query_doc_pairs = []
        for doc in documents:
            doc_text = f"{doc['source'].get('ë¬¸ì„œëª…', '')} {doc['source'].get('ì¥', '')} {doc['source'].get('ì¡°', '')} {doc['source'].get('ë¬¸ì„œë‚´ìš©', '')}"
            query_doc_pairs.append([query_text, doc_text])
        
        rerank_scores = self.reranker.compute_score(query_doc_pairs)
        
        if rerank_scores is None:
            print("ë¦¬ë­í¬ ì ìˆ˜ ê³„ì‚°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return documents[:top_k]
        elif isinstance(rerank_scores, np.ndarray):
            rerank_scores = rerank_scores.tolist()
        elif hasattr(rerank_scores, 'tolist'):
            rerank_scores = rerank_scores.tolist()
        else:
            rerank_scores = list(rerank_scores)
        
        print(f"ë¦¬ë­í¬ ì ìˆ˜ ë²”ìœ„: {min(rerank_scores):.6f} ~ {max(rerank_scores):.6f}")
        
        for i, doc in enumerate(documents):
            doc['rerank_score'] = rerank_scores[i]
        
        reranked_results = sorted(documents, key=lambda x: x['rerank_score'], reverse=True)[:top_k]
        
        return reranked_results

    def create_search_pipeline(self, pipeline_id: str = "hybrid-minmax-pipeline"):
        """
        OpenSearch 3.0+ í˜¸í™˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìš© search pipeline ìƒì„±
        """
        pipeline_body = {
            "description": "í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ì •ê·œí™” ë° ê²°í•© íŒŒì´í”„ë¼ì¸",
            "phase_results_processors": [
                {
                    "normalization-processor": {
                        "normalization": { 
                            "technique": "min_max" 
                        },
                        "combination": {
                            "technique": "arithmetic_mean",
                            "parameters": {
                                "weights": [0.3, 0.7]
                            }
                        }
                    }
                }
            ]
        }

        try:
            # íŒŒì´í”„ë¼ì¸ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸
            response = self.client.transport.perform_request(
                method="PUT",
                url=f"/_search/pipeline/{pipeline_id}",
                body=pipeline_body
            )
            print(f"âœ… Search pipeline '{pipeline_id}' ìƒì„±/ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            print(f"ì‘ë‹µ: {response}")
            return True
        except Exception as e:
            print(f"âŒ Search pipeline ìƒì„± ì‹¤íŒ¨: {e}")
            logging.error(f"Search pipeline ìƒì„± ì˜¤ë¥˜: {e}")
            return False

    def get_search_pipeline(self, pipeline_id: str = "hybrid-minmax-pipeline"):
        """
        ìƒì„±ëœ search pipeline ì •ë³´ ì¡°íšŒ
        """
        try:
            response = self.client.transport.perform_request(
                method="GET",
                url=f"/_search/pipeline/{pipeline_id}"
            )
            print(f"ğŸ“‹ Search pipeline '{pipeline_id}' ì •ë³´:")
            print(json.dumps(response, indent=2, ensure_ascii=False))
            return response
        except Exception as e:
            print(f"âŒ Search pipeline ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def delete_search_pipeline(self, pipeline_id: str = "hybrid-minmax-pipeline"):
        """
        search pipeline ì‚­ì œ
        """
        try:
            response = self.client.transport.perform_request(
                method="DELETE",
                url=f"/_search/pipeline/{pipeline_id}"
            )
            print(f"ğŸ—‘ï¸ Search pipeline '{pipeline_id}' ì‚­ì œ ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"âŒ Search pipeline ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False
    
    def search_with_pipeline(self, 
                           query_text: str,
                           keywords: Union[str, List[str]] = None, 
                           pipeline_id: str = "hybrid-minmax-pipeline", 
                           index_name: str = "pharma_test_index", 
                           top_k: int = 10,
                           use_rerank: bool = True,
                           rerank_top_k: int = 3):
        """
        Search pipelineì„ ì‚¬ìš©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        
        Args:
            query_text (str): ê²€ìƒ‰ ì¿¼ë¦¬ í…ìŠ¤íŠ¸
            keywords (Union[str, List[str]]): í‚¤ì›Œë“œ ë˜ëŠ” í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            pipeline_id (str): ì‚¬ìš©í•  search pipeline ID
            index_name (str): ê²€ìƒ‰ ëŒ€ìƒ ì¸ë±ìŠ¤
            top_k (int): ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            use_rerank (bool): ë¦¬ë­ì»¤ ì‚¬ìš© ì—¬ë¶€
            rerank_top_k (int): ë¦¬ë­í¬ í›„ ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼ (ë¦¬ë­í¬ ì ìš© ì‹œ ë¦¬ë­í¬ëœ ê²°ê³¼)
        """
        print(f"\n=== Search Pipeline ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘ ===")
        print(f"Pipeline ID: {pipeline_id}")
        print(f"Query: {query_text}")
        print(f"Keywords: {keywords}")
        
        try:
            # í‚¤ì›Œë“œ ì²˜ë¦¬
            if keywords is None:
                keyword_text = query_text
            elif isinstance(keywords, list):
                keyword_text = " ".join(keywords)
            else:
                keyword_text = keywords
            
            # ë²¡í„° ì„ë² ë”© ìƒì„±
            query_vector = self.model.encode(query_text).tolist()
            print(f"ìƒì„±ëœ ë²¡í„° ì°¨ì›: {len(query_vector)}")
            
            # í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ êµ¬ì„±
            query_body = {
                "size": top_k,
                "query": {
                    "hybrid": {
                        "queries": [
                            {
                                "multi_match": {
                                    "query": keyword_text,
                                    "fields": ["ë¬¸ì„œë‚´ìš©^2", "ë¬¸ì„œëª…^1.5", "ì¥^1.2", "ì¡°^1.0"],
                                    "type": "best_fields",
                                    "fuzziness": "AUTO"
                                }
                            },
                            {
                                "knn": {
                                    "content_vector": {
                                        "vector": query_vector,
                                        "k": top_k
                                    }
                                }
                            }
                        ]
                    }
                },
                "_source": {
                    "excludes": ["content_vector"]
                }
            }

            # Search pipeline íŒŒë¼ë¯¸í„° ì„¤ì •
            params = {"search_pipeline": pipeline_id}
            
            # print(f"ì‹¤í–‰ ì¤‘ì¸ ì¿¼ë¦¬: {json.dumps(query_body, indent=2, ensure_ascii=False)}")

            # ê²€ìƒ‰ ì‹¤í–‰
            response = self.client.search(index=index_name, body=query_body, params=params)
            
            # ê²°ê³¼ ì²˜ë¦¬
            hits = response.get("hits", {}).get("hits", [])
            results = []
            
            print(f"âœ… Search pipeline ê²€ìƒ‰ ì™„ë£Œ: {len(hits)}ê°œ ê²°ê³¼")
            
            for i, hit in enumerate(hits):
                result = {
                    "score": hit["_score"],
                    "source": hit["_source"]
                }
                results.append(result)
                
                # ê²°ê³¼ ì¶œë ¥
                source = hit["_source"]
                print(f"\n{i+1}. Pipeline ì ìˆ˜: {hit['_score']:.6f}")
                print(f"   ë¬¸ì„œëª…: {source.get('ë¬¸ì„œëª…', 'N/A')}")
                print(f"   ì¥: {source.get('ì¥', 'N/A')}")
                print(f"   ì¡°: {source.get('ì¡°', 'N/A')}")
                print(f"   ë‚´ìš©: {source.get('ë¬¸ì„œë‚´ìš©', 'N/A')[:100]}...")
            
            # ë¦¬ë­í¬ ì ìš©
            if use_rerank and results:
                print(f"\nğŸ”„ BGE Rerankerë¡œ ìƒìœ„ {rerank_top_k}ê°œ ì„ ë³„ ì¤‘...")
                reranked_results = self.rerank_documents(query_text, results, rerank_top_k)
                
                print(f"\n=== BGE Reranker ìµœì¢… ê²°ê³¼ (ìƒìœ„ {len(reranked_results)}ê°œ) ===")
                for i, doc in enumerate(reranked_results):
                    source = doc['source']
                    print(f"\n{i+1}. ë¦¬ë­í¬ ì ìˆ˜: {doc['rerank_score']:.6f}")
                    print(f"   Pipeline ì ìˆ˜: {doc['score']:.6f}")
                    print(f"   ë¬¸ì„œëª…: {source.get('ë¬¸ì„œëª…', 'N/A')}")
                    print(f"   ì¥: {source.get('ì¥', 'N/A')}")
                    print(f"   ì¡°: {source.get('ì¡°', 'N/A')}")
                    print(f"   ë‚´ìš©: {source.get('ë¬¸ì„œë‚´ìš©', 'N/A')[:100]}...")
                
                return reranked_results
            
            return results
            
        except Exception as e:
            print(f"âŒ Search pipeline ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            logging.error(f"Search pipeline ê²€ìƒ‰ ìƒì„¸ ì˜¤ë¥˜: {e}")
            return []


if __name__ == "__main__":
    # OpenSearch Hybrid Client ì´ˆê¸°í™”
    client = OpenSearchHybridClient()
    
    # ì‚¬ìš©í•  ì¸ë±ìŠ¤ì™€ íŒŒì´í”„ë¼ì¸ ID ì„¤ì •
    index_name = "pharma_test_index"  # ì‹¤ì œ ì¸ë±ìŠ¤ëª…ìœ¼ë¡œ ë³€ê²½
    pipeline_id = "hybrid-minmax-pipeline"
    
    print("=== OpenSearch 3.0+ Search Pipeline í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===\n")
    
    # 1. Search Pipeline ìƒì„±
    print("1ï¸âƒ£ Search Pipeline ìƒì„± ì¤‘...")
    pipeline_created = client.create_search_pipeline(pipeline_id)
    
    if pipeline_created:
        # 2. ìƒì„±ëœ Pipeline í™•ì¸
        print("\n2ï¸âƒ£ ìƒì„±ëœ Search Pipeline í™•ì¸...")
        client.get_search_pipeline(pipeline_id)
        
        # 3. Search Pipelineì„ ì‚¬ìš©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
        print("\n3ï¸âƒ£ Search Pipeline ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰...")
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
        test_queries = [
            {
                "query_text": "ì„ì§ì› êµìœ¡ê¸°ê°„ì´ ì–´ë–»ê²Œ ë¼?",
                "keywords": ["ì„ì§ì›", "êµìœ¡", "ê¸°ê°„"]
            },
            {
                "query_text": "íšŒì‚¬ ê·œì •ì— ëŒ€í•´ ì•Œë ¤ì¤˜",
                "keywords": ["íšŒì‚¬", "ê·œì •"]
            }
        ]
        
        for i, test_query in enumerate(test_queries, 1):
            print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ {i}: {test_query['query_text']}")
            
            # Search Pipeline ê¸°ë°˜ ê²€ìƒ‰ (ë¦¬ë­í¬ í¬í•¨)
            final_results = client.search_with_pipeline(
                query_text=test_query["query_text"],
                keywords=test_query["keywords"],
                pipeline_id=pipeline_id,
                index_name=index_name,
                top_k=5,
                use_rerank=True,
                rerank_top_k=3
            )
            
            print(f"ğŸ¯ ìµœì¢… ê²°ê³¼: {len(final_results)}ê°œ ë¬¸ì„œ ë°˜í™˜")
            print("-" * 80)
            
    else:
        print("âŒ Search Pipeline ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("OpenSearch ë²„ì „ì„ í™•ì¸í•˜ê³  search pipeline ê¸°ëŠ¥ì´ ì§€ì›ë˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    print("\n=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")