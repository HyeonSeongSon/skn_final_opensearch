"""
ì œì•½íšŒì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

main.pyì˜ OpenSearchClientë¥¼ ì‚¬ìš©í•˜ì—¬:
1. ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ
2. ìƒˆ ì¸ë±ìŠ¤ ìƒì„± (BGE Reranker ì§€ì›)
3. JSONL íŒŒì¼ë“¤ì—ì„œ ë¬¸ì„œ ë¡œë“œ
4. ë¬¸ì„œì— ì„ë² ë”© ë²¡í„° ì¶”ê°€
5. OpenSearchì— ë¬¸ì„œ ìƒ‰ì¸
6. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + BGE Rerankerë¡œ ìƒìœ„ 3ê°œ ë¬¸ì„œ ì¶”ì¶œ
"""

from opensearch import OpenSearchClient
import glob
import time
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*80)
    print("ì œì•½íšŒì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ ì‹œì‘")
    print("="*80)
    
    # 1. OpenSearchClient ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    print("\n1. OpenSearch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
    client = OpenSearchClient()
    
    if not client.client:
        print("âŒ OpenSearch ì—°ê²° ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # ëª¨ë¸ ì°¨ì› í™•ì¸
    vec_dim = len(client.model.encode("dummy_text"))
    print(f"ì„ë² ë”© ëª¨ë¸ ì°¨ì›: {vec_dim}")
    
    # 2. ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ
    print("\n2. ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ ì¤‘...")
    client.delete_index("internal_regulations_index")
    
    # 3. ìƒˆ ì¸ë±ìŠ¤ ìƒì„± (BGE Rerankerì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì§€ì›)
    print("\n3. ìƒˆ ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
    mapping = {
        "settings": {
            "index": {
                "knn": True  # k-NN ê²€ìƒ‰ í™œì„±í™”
            }
        },
        "mappings": {
            "properties": {
                "ë¬¸ì„œëª…":    { "type": "keyword" },  # ì •í™•í•œ ë¬¸ì„œëª… ë§¤ì¹­
                "ì¥":      { "type": "text" },      # ì „ë¬¸ ê²€ìƒ‰ ê°€ëŠ¥
                "ì¡°":      { "type": "text" },      # ì „ë¬¸ ê²€ìƒ‰ ê°€ëŠ¥
                "ë¬¸ì„œë‚´ìš©":  { "type": "text" },      # ì „ë¬¸ ê²€ìƒ‰ ê°€ëŠ¥
                "ì¶œì²˜íŒŒì¼":  { "type": "keyword" },   # ì •í™•í•œ íŒŒì¼ëª… ë§¤ì¹­
                "content_vector": {
                    "type": "knn_vector",           # ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ìš©
                    "dimension": vec_dim,
                    "method": {
                        "name": "hnsw",             # Hierarchical Navigable Small World
                        "space_type": "cosinesimil", # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©
                        "engine": "lucene"          # ê²€ìƒ‰ ì—”ì§„ (nmslib deprecated)
                    }
                }
            }
        }
    }
    
    success = client.create_index_with_mapping("internal_regulations_index", mapping)
    if not success:
        print("âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # 4. JSONL íŒŒì¼ë“¤ ìë™ íƒì§€ ë° ë¡œë“œ
    print("\n4. JSONL íŒŒì¼ë“¤ì—ì„œ ë¬¸ì„œ ë¡œë“œ ì¤‘...")
    jsonl_files = glob.glob("*.jsonl")
    print(f"ë°œê²¬ëœ JSONL íŒŒì¼ë“¤: {jsonl_files}")
    
    if not jsonl_files:
        print("âŒ JSONL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    all_docs = []
    for jsonl_file in jsonl_files:
        print(f"\nì²˜ë¦¬ ì¤‘: {jsonl_file}")
        docs = client.load_documents_from_jsonl(jsonl_file)
        print(f"  - ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")
        
        # 5. ê° ë¬¸ì„œì— ì„ë² ë”© ë²¡í„° ìƒì„± ë° ì¶œì²˜ ì •ë³´ ì¶”ê°€
        for doc in docs:
            text = doc.get("ë¬¸ì„œë‚´ìš©", "")
            if text:
                # KURE-v1 ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„± (1024ì°¨ì›)
                embedding = client.model.encode(text)
                doc["content_vector"] = embedding.tolist()  # type: ignore
            
            # ì¶œì²˜ íŒŒì¼ ì •ë³´ ì¶”ê°€
            doc["ì¶œì²˜íŒŒì¼"] = jsonl_file
        
        all_docs.extend(docs)
        print(f"  - ì„ë² ë”© ì™„ë£Œ: {len(docs)}ê°œ")
    
    print(f"\nì´ ì²˜ë¦¬ëœ ë¬¸ì„œ ìˆ˜: {len(all_docs)}")
    
    # 6. OpenSearchì— ë¬¸ì„œ ìƒ‰ì¸
    print("\n6. OpenSearchì— ë¬¸ì„œ ìƒ‰ì¸ ì¤‘...")
    success = client.bulk_index_documents("internal_regulations_index", all_docs, refresh=True)
    
    if not success:
        print("âŒ ë¬¸ì„œ ìƒ‰ì¸ ì‹¤íŒ¨.")
        return
    
    print("âœ… ë¬¸ì„œ ìƒ‰ì¸ ì™„ë£Œ!")
    
    # ìƒ‰ì¸ ì™„ë£Œ ëŒ€ê¸°
    print("ìƒ‰ì¸ ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
    time.sleep(2)
    
    # 7. ìƒ‰ì¸ ê²€ì¦
    print("\n7. ìƒ‰ì¸ ê²€ì¦ ì¤‘...")
    query = {"query": {"match_all": {}}}
    results = client.search_document("internal_regulations_index", query)
    print(f"âœ… ì „ì²´ ìƒ‰ì¸ëœ ë¬¸ì„œ ìˆ˜: {len(results)}ê°œ")
    
    # 8. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + BGE Reranker í…ŒìŠ¤íŠ¸
    print("\n" + "="*80)
    print("8. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + BGE Reranker í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_keywords = ["ì‹ ì…ì‚¬ì›", "êµìœ¡", "ê¸°ê°„"]
    test_query = "ì‹ ì…ì‚¬ì› êµìœ¡ ê¸°ê°„ì´ ì–´ë–»ê²Œ ë¼?"
    
    print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{test_query}'")
    print(f"ğŸ” í‚¤ì›Œë“œ: {test_keywords}")
    
    # ì •ê·œí™”ëœ í•˜ì´ë¸Œë¦¬ë“œ ì„œì¹˜ + BGE Rerankerë¡œ ìƒìœ„ 3ê°œ ì¶”ì¶œ
    final_results = client.normalized_hybrid_search(
        keywords=test_keywords,
        query_text=test_query,
        top_k=10,           # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ 10ê°œ ì¶”ì¶œ
        bm25_weight=0.3,    # BM25 ê°€ì¤‘ì¹˜
        vector_weight=0.7,  # ë²¡í„° ê°€ì¤‘ì¹˜  
        use_rerank=True,    # BGE Reranker ì‚¬ìš©
        rerank_top_k=3      # ìµœì¢… ìƒìœ„ 3ê°œ ì¶œë ¥
    )
    
    if final_results:
        print(f"\nğŸ¯ ìµœì¢… ê²€ìƒ‰ ì™„ë£Œ! ìƒìœ„ {len(final_results)}ê°œ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    print("\n" + "="*80)
    print("ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ!")
    print("="*80)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\ní”„ë¡œê·¸ë¨ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logging.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True) 